{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy_indexed as npi\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "#os.chdir('/Users/hausfath/Desktop/Climate Science/Model GCM Comparison/Old Models Project/')\n",
    "\n",
    "forcing_file = 'forcing_data/1750-Oct2017_forcings.idlsave'\n",
    "temps_file = 'combined_temps_Jan_2019.csv'\n",
    "models_file = 'Model_obs_comps.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'combined_temps_Jan_2019.csv' does not exist: b'combined_temps_Jan_2019.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1959544efbf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mforcings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadsav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforcing_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpython_dict\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtemps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemps_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mannual_temps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mannual_temps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannual_temps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hadcrut4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gistemp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'noaa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'berkeley'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cowtan_way'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'combined_temps_Jan_2019.csv' does not exist: b'combined_temps_Jan_2019.csv'"
     ]
    }
   ],
   "source": [
    "#Import forcings and temperatures. Replace month temperatures with annual means.\n",
    "\n",
    "forcings = spio.readsav(forcing_file, python_dict =True, verbose=False)\n",
    "temps = pd.read_csv(temps_file)\n",
    "annual_temps = temps.groupby('year').mean()\n",
    "annual_temps = annual_temps.reset_index()[['year', 'hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']]\n",
    "single_models = pd.read_excel(models_file, sheet_name = 'Individual papers')\n",
    "single_models.columns = map(str.lower, single_models.columns)\n",
    "\n",
    "timeframes = ([1970, 2000], [1971, 2000], [1972, 2000], [1975, 2010], [1977, 2017], \n",
    "              [1981, 2017], [1988, 2017], [1990, 2017], [1993, 2017], [1995, 2017], \n",
    "              [2001, 2017], [2007, 2017])\n",
    "model_names = ['manabe_1970', 'mitchell_1970', 'benson_1970', 'rasool_schneider_1971', 'sawyer_1972', \n",
    "               'broecker_1975', 'nordhaus_1977', 'schneider_thompson_1981', 'hansen_1981_1', 'hansen_1981_2a', \n",
    "               'hansen_1988_a', 'hansen_1988_b', 'hansen_1988_c', 'manabe_stouffer_1993', 'far_ebm_best', \n",
    "               'far_ebm_high', 'far_ebm_low', 'sar_ebm_best', 'sar_ebm_high', 'sar_ebm_low', 'tar_ebm_best', \n",
    "               'tar_ebm_high', 'tar_ebm_low', 'ar4_mmm_best', 'ar4_mmm_high', 'ar4_mmm_low']\n",
    "\n",
    "model_years = ([1970, 2000], [1970, 2000], [1970, 2000], [1971, 2000], [1972, 2000], [1975, 2010], [1977, 2017], \n",
    "              [1981, 2017], [1981, 2017], [1981, 2017], [1988, 2017], [1988, 2017], [1988, 2017], [1993, 2017],\n",
    "              [1990, 2017], [1990, 2017], [1990, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [2001, 2017], \n",
    "              [2001, 2017], [2001, 2017], [2007, 2017], [2007, 2017], [2007, 2017])\n",
    "\n",
    "ipcc_models = ['FAR EMB', 'FAR GFDL', 'FAR UKMET', 'SAR EMB', 'SAR MP01GG01', 'SAR CS01GG01', 'SAR GF01GG01', \n",
    "               'SAR DK01GG01', 'SAR NC01GG01', 'SAR HC02GG01', 'SAR HC01GG01', 'SAR HC01GG02', 'SAR HC01GG03', \n",
    "               'SAR HC01GG04', 'SAR NI01GG01', 'SAR CC01GG01', 'TAR EBM', 'TAR EH4OPYC_A2', 'TAR HADCM3_A2', \n",
    "               'TAR CSIRO_A2', 'TAR NCAR-CSM_A2', 'TAR CGCM2_A2', 'TAR CCSRNIES_A2']\n",
    "\n",
    "ipcc_years = ([1990, 2017], [1990, 2017], [1990, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], \n",
    "              [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], \n",
    "              [1995, 2017], [1995, 2017], [2001, 2017], [2001, 2017], [2001, 2017], [2001, 2017], [2001, 2017], \n",
    "              [2001, 2017], [2001, 2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_arma_cis(y_data, x_data, runtype='ar1'):\n",
    "    '''\n",
    "    Calculate coefficients using OLS and CIs via AR[1]\n",
    "    '''\n",
    "    X = x_data\n",
    "    X = sm.add_constant(X)\n",
    "    smresults = smf.OLS(y_data, X).fit()\n",
    "    ols_coef = smresults.params[1]\n",
    "    model = ARIMA(y_data, exog=x_data, order=(1,0,0)).fit(disp=0)\n",
    "    arma_coef = model.params[1]\n",
    "    \n",
    "    ols_ci = ols_coef - smresults.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "    arma_ci = arma_coef - model.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "    if arma_ci > ols_ci:\n",
    "        ci_lower = model.conf_int(alpha=0.05, cols=None)[0][1] - arma_coef + ols_coef\n",
    "        ci_upper = model.conf_int(alpha=0.05, cols=None)[1][1] - arma_coef + ols_coef\n",
    "    else:\n",
    "        ci_lower = smresults.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "        ci_upper = smresults.conf_int(alpha=0.05, cols=None)[1][1]\n",
    "    if runtype == 'ols':\n",
    "        ci_lower = smresults.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "        ci_upper = smresults.conf_int(alpha=0.05, cols=None)[1][1]\n",
    "    sd = (ci_upper - ols_coef) / 2.\n",
    "    return {\n",
    "            'coef' : ols_coef,\n",
    "            'ci_lower' : ci_lower,\n",
    "            'ci_upper' : ci_upper,\n",
    "            'sd' : sd\n",
    "    }\n",
    "\n",
    "\n",
    "def obs_temp_time_trends(annual_temps, timeframes):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe = [], [], [], []\n",
    "    for times in timeframes:\n",
    "        print('Analyzing the period from ', times[0], ' to ', times[1])\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        start_year = times[0]\n",
    "        end_year = times[1]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= end_year))[0]\n",
    "\n",
    "        for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "            years = annual_temps['year'][temp_year_range]\n",
    "            temp_values = annual_temps[obs_temps][temp_year_range]\n",
    "            results = coef_arma_cis(temp_values, years)\n",
    "            coef.append(results['coef'])\n",
    "            ci_lower.append(results['ci_lower'])\n",
    "            ci_upper.append(results['ci_upper'])\n",
    "            obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(times))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv('obs_time_trends.csv')\n",
    "\n",
    "\n",
    "def obs_temp_forcing_trends(forcings, annual_temps, timeframes):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe = [], [], [], []\n",
    "\n",
    "    for times in timeframes:\n",
    "        print('Analyzing the period from ', times[0], ' to ', times[1])\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        start_year = times[0]\n",
    "        end_year = times[1]\n",
    "        rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "        rf_year_range = np.where((forcings['year'] >= start_year) & (forcings['year'] <= end_year))[0]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= end_year))[0]\n",
    "        \n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                rf_values = rf_anthro[rf_num][rf_year_range]\n",
    "                temp_values = annual_temps[obs_temps][temp_year_range]\n",
    "                results = coef_arma_cis(temp_values, rf_values, runtype='ols')\n",
    "                coef.append(results['coef'])\n",
    "                ci_lower.append(results['ci_lower'])\n",
    "                ci_upper.append(results['ci_upper'])\n",
    "                rf_number.append(rf_num)\n",
    "                obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'rf_number' : rf_number,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(times))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv('obs_forcing_trends.csv')\n",
    "\n",
    "\n",
    "def models_forcing_time_trends(single_models, model_names, model_years):\n",
    "    coef, coef_low, coef_high, timeframe, model, dtype = [], [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        temp_year = coef_arma_cis(single_models[model_names[i]+'_t'][years], single_models['year'][years])\n",
    "        temp_forcing = coef_arma_cis(single_models[model_names[i]+'_t'][years], single_models[model_names[i]+'_f'][years], runtype='ols')\n",
    "        coef.append(temp_year['coef'])\n",
    "        coef_low.append(temp_year['ci_lower'])\n",
    "        coef_high.append(temp_year['ci_upper'])\n",
    "        timeframe.append(str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        model.append(model_names[i])\n",
    "        dtype.append('model_time')\n",
    "        coef.append(temp_forcing['coef'])\n",
    "        coef_low.append(temp_forcing['ci_lower'])\n",
    "        coef_high.append(temp_forcing['ci_upper'])\n",
    "        timeframe.append(str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        model.append(model_names[i])\n",
    "        dtype.append('model_forcing')\n",
    "    #manabe_1970_f = coef_arma_cis(df['manabe_1970_t'], df['manabe_1970_f'])\n",
    "    \n",
    "    df = pd.DataFrame({'coef' : coef,\n",
    "                       'coef_low' : coef_low,\n",
    "                       'coef_high' : coef_high,\n",
    "                       'timeframe' : timeframe,\n",
    "                       'model' : model,\n",
    "                       'dtype': dtype})\n",
    "    df.to_csv('single_model_trends.csv')\n",
    "\n",
    "\n",
    "def model_obs_time_diffs(single_models, model_names, model_years, annual_temps):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe, model = [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        coef, ci_lower, ci_upper = [], [], []\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "            print('Analyzing '+model_names[i]+' '+obs_temps+' diffs from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "            model_obs_diff = single_models[model_names[i]+'_t'][years] - annual_temps[obs_temps][years]            \n",
    "            results = coef_arma_cis(model_obs_diff, single_models['year'][years])\n",
    "            coef.append(results['coef'])\n",
    "            ci_lower.append(results['ci_lower'])\n",
    "            ci_upper.append(results['ci_upper'])\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv('model_obs_time_diffs.csv')    \n",
    "\n",
    "#obs_temp_time_trends(annual_temps, timeframes)\n",
    "#obs_temp_forcing_trends(forcings, annual_temps, timeframes)\n",
    "#models_forcing_time_trends(single_models, model_names, model_years)\n",
    "#model_obs_time_diffs(single_models, model_names, model_years, annual_temps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annual_temps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1b0303485740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_temps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'forcings'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0moutput_forcing_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforcings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannual_temps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1970\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'annual_temps' is not defined"
     ]
    }
   ],
   "source": [
    "def output_forcing_ensemble(forcings, annual_temps, start_year, anom_period):\n",
    "    rf_year_range = np.where((forcings['year'] >= start_year) & (forcings['year'] <= 2017))[0]\n",
    "    temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= 2017))[0]\n",
    "    rf_anthro = forcings['rf_anthro'][rf_year_range]\n",
    "    rf_anthro_anoms = rf_anthro - rf_anthro[0:anom_period].mean(axis=0)\n",
    "    rf_anthro_anoms = np.swapaxes(rf_anthro_anoms,0,1)\n",
    "\n",
    "    df_names = ('hadcrut4_df', 'gistemp_df', 'noaa_df', 'berkeley_df', 'cowtan_way_df')\n",
    "    dfs ={}\n",
    "\n",
    "    for df_names,obs_temps in zip(df_names, ['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "        dfs[df_names] = pd.DataFrame()\n",
    "        dfs[df_names]['year'] = annual_temps['year'][temp_year_range]\n",
    "        temps = annual_temps[obs_temps][temp_year_range].values\n",
    "        anoms = temps - temps[0:anom_period].mean(axis=0)\n",
    "        dfs[df_names]['temp'] = anoms\n",
    "        for rf_num in range(1000):\n",
    "            dfs[df_names]['forcing_'+str(rf_num)] = rf_anthro_anoms[rf_num]\n",
    "        \n",
    "        dfs[df_names].to_csv(obs_temps + '_' + 'forcings'+str(start_year)+'.csv')\n",
    "\n",
    "output_forcing_ensemble(forcings, annual_temps, 1970, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1970  to  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  newparams = ((1-np.exp(-params))/\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:607: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (1+np.exp(-params))).copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1971  to  2000\n",
      "Analyzing the period from  1972  to  2000\n",
      "Analyzing the period from  1975  to  2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:634: RuntimeWarning: divide by zero encountered in log\n",
      "  invarcoefs = -np.log((1-params)/(1+params))\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/kalmanf/kalmanfilter.py:654: RuntimeWarning: divide by zero encountered in log\n",
      "  R_mat, T_mat)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:243: RuntimeWarning: invalid value encountered in subtract\n",
      "  **kwargs)).imag/2./hess[i, j]\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  **kwargs)).imag/2./hess[i, j]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1977  to  2017\n",
      "Analyzing the period from  1981  to  2017\n",
      "Analyzing the period from  1988  to  2017\n",
      "Analyzing the period from  1990  to  2017\n",
      "Analyzing the period from  1993  to  2017\n",
      "Analyzing the period from  1995  to  2017\n",
      "Analyzing the period from  2001  to  2017\n",
      "Analyzing the period from  2007  to  2017\n"
     ]
    }
   ],
   "source": [
    "def model_forcing_rate(single_models, model_names, model_years):\n",
    "    coef, coef_low, coef_high, timeframe, model = [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        forcing_rate = coef_arma_cis(single_models[model_names[i]+'_f'][years], single_models['year'][years])\n",
    "        coef.append(forcing_rate['coef'])\n",
    "        coef_low.append(forcing_rate['ci_lower'])\n",
    "        coef_high.append(forcing_rate['ci_upper'])\n",
    "        timeframe.append(str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        model.append(model_names[i])\n",
    "    #manabe_1970_f = coef_arma_cis(df['manabe_1970_t'], df['manabe_1970_f'])\n",
    "    \n",
    "    df = pd.DataFrame({'coef' : coef,\n",
    "                       'coef_low' : coef_low,\n",
    "                       'coef_high' : coef_high,\n",
    "                       'timeframe' : timeframe,\n",
    "                       'model' : model})\n",
    "    df.to_csv('single_model_forcing_rate.csv')\n",
    "    \n",
    "\n",
    "def obs_forcing_rate(forcings, annual_temps, timeframes):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe = [], [], [], []\n",
    "    \n",
    "    for times in timeframes:\n",
    "        print('Analyzing the period from ', times[0], ' to ', times[1])\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        start_year = times[0]\n",
    "        end_year = times[1]\n",
    "        rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "        rf_year_range = np.where((forcings['year'] >= start_year) & (forcings['year'] <= end_year))[0]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= end_year))[0]\n",
    "        \n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                rf_values = rf_anthro[rf_num][rf_year_range]\n",
    "                years = annual_temps['year'][temp_year_range]\n",
    "                results = coef_arma_cis(rf_values, years)\n",
    "                coef.append(results['coef'])\n",
    "                ci_lower.append(results['ci_lower'])\n",
    "                ci_upper.append(results['ci_upper'])\n",
    "                rf_number.append(rf_num)\n",
    "                obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'rf_number' : rf_number,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(times))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv('obs_forcing_rate.csv')\n",
    "\n",
    "#model_forcing_rate(single_models, model_names, model_years)\n",
    "obs_forcing_rate(forcings, annual_temps, timeframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_forcing_timeseries(forcings):\n",
    "    forcings['rf_total'].shape\n",
    "    std = np.std(forcings['rf_total'], axis=1)\n",
    "    mean = np.mean(forcings['rf_total'], axis=1)\n",
    "    \n",
    "    df = pd.DataFrame({'year' : forcings['year'],\n",
    "                       'forcing_mean' : mean,\n",
    "                       'forcing_std' : std})\n",
    "    df.to_csv('forcing_timeseries.csv')\n",
    "\n",
    "obs_forcing_timeseries(forcings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing manabe_1970 from 1970 to 2000\n",
      "Analyzing mitchell_1970 from 1970 to 2000\n",
      "Analyzing benson_1970 from 1970 to 2000\n",
      "Analyzing rasool_schneider_1971 from 1971 to 2000\n",
      "Analyzing sawyer_1972 from 1972 to 2000\n",
      "Analyzing broecker_1975 from 1975 to 2010\n",
      "Analyzing nordhaus_1977 from 1977 to 2017\n",
      "Analyzing schneider_thompson_1981 from 1981 to 2017\n",
      "Analyzing hansen_1981_1 from 1981 to 2017\n",
      "Analyzing hansen_1981_2a from 1981 to 2017\n",
      "Analyzing hansen_1988_a from 1988 to 2017\n",
      "Analyzing hansen_1988_b from 1988 to 2017\n",
      "Analyzing hansen_1988_c from 1988 to 2017\n",
      "Analyzing manabe_stouffer_1993 from 1993 to 2017\n",
      "Analyzing far_ebm_best from 1990 to 2017\n",
      "Analyzing far_ebm_high from 1990 to 2017\n",
      "Analyzing far_ebm_low from 1990 to 2017\n",
      "Analyzing sar_ebm_best from 1995 to 2017\n",
      "Analyzing sar_ebm_high from 1995 to 2017\n",
      "Analyzing sar_ebm_low from 1995 to 2017\n",
      "Analyzing tar_ebm_best from 2001 to 2017\n",
      "Analyzing tar_ebm_high from 2001 to 2017\n",
      "Analyzing tar_ebm_low from 2001 to 2017\n",
      "Analyzing ar4_mmm_best from 2007 to 2017\n",
      "Analyzing ar4_mmm_high from 2007 to 2017\n",
      "Analyzing ar4_mmm_low from 2007 to 2017\n"
     ]
    }
   ],
   "source": [
    "def model_skill(obs_trend, pred_trend):\n",
    "    skill = 1 - ((obs_trend - pred_trend)**2 / obs_trend**2) ** (0.5)\n",
    "    return skill\n",
    "\n",
    "\n",
    "def model_time_skill_scores(single_models, model_names, model_years, annual_temps):\n",
    "    skill_mean, skill_median, skill_5th, skill_95th, timeframe, model = [], [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        skill = []\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        model_trend = coef_arma_cis(single_models[model_names[i]+'_t'][years], single_models['year'][years])\n",
    "        for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "            print('Analyzing '+model_names[i]+' '+obs_temps+' diffs from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "            obs_trend = coef_arma_cis(annual_temps[obs_temps][years], annual_temps['year'][years])\n",
    "            model_monte_carlo = np.random.normal(model_trend['coef'], model_trend['sd'], 100)\n",
    "            obs_monte_carlo = np.random.normal(obs_trend['coef'], obs_trend['sd'], 100)\n",
    "            for j in range(100):\n",
    "                skill.append(model_skill(obs_monte_carlo[j], model_monte_carlo[j]))\n",
    "        df = pd.DataFrame({'skill' : skill})\n",
    "        skill_mean.append(df['skill'].mean())\n",
    "        skill_median.append(df['skill'].median())\n",
    "        skill_5th.append(df['skill'].quantile(0.05))\n",
    "        skill_95th.append(df['skill'].quantile(0.95))    \n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))\n",
    "    \n",
    "    df = pd.DataFrame({'skill_mean' : skill_mean,\n",
    "                       'skill_median' : skill_median,\n",
    "                       'skill_5th' : skill_5th,\n",
    "                       'skill_95th' : skill_95th,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    df.to_csv('model_time_skill_scores.csv')    \n",
    "    \n",
    "\n",
    "def model_tcr_skill_scores(single_models, model_names, model_years, annual_temps, forcings):\n",
    "    skill_mean, skill_median, skill_5th, skill_95th, timeframe, model = [], [], [], [], [], []\n",
    "    rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        skill = []\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        model_t = single_models[model_names[i]+'_t'][years]\n",
    "        model_f = single_models[model_names[i]+'_f'][years]\n",
    "        model_tcr = coef_arma_cis(model_t, model_f, runtype='ols')\n",
    "        rf_year_range = np.where((forcings['year'] >= model_years[i][0]) & (forcings['year'] <= model_years[i][1]))[0]\n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                obs_f = rf_anthro[rf_num][rf_year_range]\n",
    "                obs_t = annual_temps[obs_temps][years]\n",
    "                obs_tcr = coef_arma_cis(obs_t, obs_f, runtype='ols')\n",
    "                model_monte_carlo = np.random.normal(model_tcr['coef'], model_tcr['sd'], 100)\n",
    "                obs_monte_carlo = np.random.normal(obs_tcr['coef'], obs_tcr['sd'], 100)\n",
    "                for j in range(100):\n",
    "                    skill.append(model_skill(obs_monte_carlo[j], model_monte_carlo[j]))\n",
    "        df = pd.DataFrame({'skill' : skill})\n",
    "        skill_mean.append(df['skill'].mean())\n",
    "        skill_median.append(df['skill'].median())        \n",
    "        skill_5th.append(df['skill'].quantile(0.05))\n",
    "        skill_95th.append(df['skill'].quantile(0.95))        \n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))\n",
    "    \n",
    "    df = pd.DataFrame({'skill_mean' : skill_mean,\n",
    "                       'skill_median' : skill_median,\n",
    "                       'skill_5th' : skill_5th,\n",
    "                       'skill_95th' : skill_95th,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    df.to_csv('model_tcr_skill_scores.csv')    \n",
    "    \n",
    "    \n",
    "\n",
    "#model_time_skill_scores(single_models, model_names, model_years, annual_temps)\n",
    "model_tcr_skill_scores(single_models, model_names, model_years, annual_temps, forcings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_obs_forcing_diffs(single_models, model_names, model_years, forcings, annual_temps):\n",
    "    #TODO: Regressing temp differences on forcing differences doesn't make sense. Figure out how to do this!\n",
    "    coef_mean, coef_sd, ci_mean, timeframe, model = [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' diffs from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        model_year_range = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "        rf_year_range = np.where((forcings['year'] >= model_years[i][0]) & (forcings['year'] <= model_years[i][1]))[0]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= model_years[i][0]) & (annual_temps['year'] <= model_years[i][1]))[0]\n",
    "        model_temp = single_models[model_names[i]+'_t'][model_year_range]\n",
    "        model_rf = single_models[model_names[i]+'_f'][model_year_range]\n",
    "\n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                obs_rf = rf_anthro[rf_num][rf_year_range]\n",
    "                obs_temp = annual_temps[obs_temps][temp_year_range]\n",
    "                temp_diff = model_temp - obs_temp\n",
    "                rf_diff = model_rf - obs_rf\n",
    "                results = coef_arma_cis(temp_diff, rf_diff, runtype='ols')\n",
    "                coef.append(results['coef'])\n",
    "                ci_lower.append(results['ci_lower'])\n",
    "                ci_upper.append(results['ci_upper'])\n",
    "                rf_number.append(rf_num)\n",
    "                obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'rf_number' : rf_number,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv('model_obs_forcing_trend_diffs.csv')\n",
    "\n",
    "#model_obs_forcing_diffs(single_models, model_names, model_years, forcings, annual_temps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
