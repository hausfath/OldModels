{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy_indexed as npi\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "forcing_file = '../data/raw/forcing_data/1750-Oct2017_forcings.idlsave'\n",
    "temps_file = '../data/raw/obs_temp_data/combined_temps_Jan_2019.csv'\n",
    "models_file = '../data/raw/model_temp_data/Model timeseries.xlsx'\n",
    "\n",
    "interim_path = \"../data/interim/\" # save interim data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/OldModels/lib/python3.8/site-packages/xlrd/xlsx.py:266: DeprecationWarning: This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead.\n",
      "  for elem in self.tree.iter() if Element_has_iter else self.tree.getiterator():\n"
     ]
    }
   ],
   "source": [
    "#Import forcings and temperatures. Replace month temperatures with annual means.\n",
    "\n",
    "forcings = spio.readsav(forcing_file, python_dict =True, verbose=False)\n",
    "temps = pd.read_csv(temps_file)\n",
    "annual_temps = temps.groupby('year').mean()\n",
    "annual_temps = annual_temps.reset_index()[['year', 'hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']]\n",
    "single_models = pd.read_excel(models_file, sheet_name = 'Individual papers')\n",
    "single_models.columns = map(str.lower, single_models.columns)\n",
    "\n",
    "timeframes = ([1970, 2000], [1971, 2000], [1972, 2000], [1975, 2010], [1977, 2017], \n",
    "              [1981, 2017], [1988, 2017], [1990, 2017], [1993, 2017], [1995, 2017], \n",
    "              [2001, 2017], [2007, 2017])\n",
    "model_names = ['manabe_1970', 'mitchell_1970', 'benson_1970', 'rasool_schneider_1971', 'sawyer_1972', \n",
    "               'broecker_1975', 'nordhaus_1977', 'schneider_thompson_1981', 'hansen_1981_1', 'hansen_1981_2a', \n",
    "               'hansen_1988_a', 'hansen_1988_b', 'hansen_1988_c', 'manabe_stouffer_1993', 'far_ebm_best', \n",
    "               'far_ebm_high', 'far_ebm_low', 'sar_ebm_best', 'sar_ebm_high', 'sar_ebm_low', 'tar_ebm_best', \n",
    "               'tar_ebm_high', 'tar_ebm_low', 'ar4_mmm_best', 'ar4_mmm_high', 'ar4_mmm_low']\n",
    "\n",
    "model_years = ([1970, 2000], [1970, 2000], [1970, 2000], [1971, 2000], [1972, 2000], [1975, 2010], [1977, 2017], \n",
    "              [1981, 2017], [1981, 2017], [1981, 2017], [1988, 2017], [1988, 2017], [1988, 2017], [1993, 2017],\n",
    "              [1990, 2017], [1990, 2017], [1990, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [2001, 2017], \n",
    "              [2001, 2017], [2001, 2017], [2007, 2017], [2007, 2017], [2007, 2017])\n",
    "\n",
    "ipcc_models = ['FAR EMB', 'FAR GFDL', 'FAR UKMET', 'SAR EMB', 'SAR MP01GG01', 'SAR CS01GG01', 'SAR GF01GG01', \n",
    "               'SAR DK01GG01', 'SAR NC01GG01', 'SAR HC02GG01', 'SAR HC01GG01', 'SAR HC01GG02', 'SAR HC01GG03', \n",
    "               'SAR HC01GG04', 'SAR NI01GG01', 'SAR CC01GG01', 'TAR EBM', 'TAR EH4OPYC_A2', 'TAR HADCM3_A2', \n",
    "               'TAR CSIRO_A2', 'TAR NCAR-CSM_A2', 'TAR CGCM2_A2', 'TAR CCSRNIES_A2']\n",
    "\n",
    "ipcc_years = ([1990, 2017], [1990, 2017], [1990, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], \n",
    "              [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], [1995, 2017], \n",
    "              [1995, 2017], [1995, 2017], [2001, 2017], [2001, 2017], [2001, 2017], [2001, 2017], [2001, 2017], \n",
    "              [2001, 2017], [2001, 2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1970  to  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/OldModels/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:214: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  warnings.warn('An unsupported index was provided and will be'\n",
      "/anaconda3/envs/OldModels/lib/python3.8/site-packages/statsmodels/base/model.py:511: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warn(\"Maximum Likelihood optimization failed to converge. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1971  to  2000\n",
      "Analyzing the period from  1972  to  2000\n",
      "Analyzing the period from  1975  to  2010\n",
      "Analyzing the period from  1977  to  2017\n",
      "Analyzing the period from  1981  to  2017\n",
      "Analyzing the period from  1988  to  2017\n",
      "Analyzing the period from  1990  to  2017\n",
      "Analyzing the period from  1993  to  2017\n",
      "Analyzing the period from  1995  to  2017\n",
      "Analyzing the period from  2001  to  2017\n",
      "Analyzing the period from  2007  to  2017\n",
      "Analyzing the period from  1970  to  2000\n",
      "Analyzing the period from  1971  to  2000\n",
      "Analyzing the period from  1972  to  2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7157382a7457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0mobs_temp_time_trends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannual_temps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0mobs_temp_forcing_trends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforcings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannual_temps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0mmodels_forcing_time_trends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_years\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0mmodel_obs_time_diffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_years\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannual_temps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7157382a7457>\u001b[0m in \u001b[0;36mobs_temp_forcing_trends\u001b[0;34m(forcings, annual_temps, timeframes)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mrf_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_anthro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrf_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrf_year_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mtemp_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannual_temps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs_temps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp_year_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoef_arma_cis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ols'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mcoef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mci_lower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ci_lower'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7157382a7457>\u001b[0m in \u001b[0;36mcoef_arma_cis\u001b[0;34m(y_data, x_data, runtype)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msmresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mols_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0marma_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, trend, method, transparams, solver, maxiter, full_output, disp, callback, start_ar_lags, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# estimate starting parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             start_params = self._fit_start_params((k_ar, k_ma, k), method,\n\u001b[0m\u001b[1;32m    938\u001b[0m                                                   start_ar_lags)\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m_fit_start_params\u001b[0;34m(self, order, method, start_ar_lags)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invtransparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             mlefit = optimize.fmin_l_bfgs_b(func, start_params,\n\u001b[0m\u001b[1;32m    559\u001b[0m                                             \u001b[0mapprox_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                             \u001b[0mpgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    196\u001b[0m             'maxls': maxls}\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0m\u001b[1;32m    199\u001b[0m                            **opts)\n\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_start_params_hr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_ar_lags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use CSS to get start params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;31m#start_params = [.1]*(k_ar+k_ma+k_exog) # different one for k?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_start_params_hr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_ar_lags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/OldModels/lib/python3.8/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36mloglike_css\u001b[0;34m(self, params, set_sigma2)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_ar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0mssr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m         \u001b[0msigma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset_sigma2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def coef_arma_cis(y_data, x_data, runtype='ar1'):\n",
    "    '''\n",
    "    Calculate coefficients using OLS and CIs via AR[1]\n",
    "    '''\n",
    "    X = x_data\n",
    "    X = sm.add_constant(X)\n",
    "    smresults = sm.OLS(y_data, X).fit()\n",
    "    ols_coef = smresults.params[1]\n",
    "    model = ARIMA(y_data, exog=x_data, order=(1,0,0)).fit(disp=0)\n",
    "    arma_coef = model.params[1]\n",
    "    \n",
    "    ols_ci = ols_coef - smresults.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "    arma_ci = arma_coef - model.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "    if arma_ci > ols_ci:\n",
    "        ci_lower = model.conf_int(alpha=0.05, cols=None)[0][1] - arma_coef + ols_coef\n",
    "        ci_upper = model.conf_int(alpha=0.05, cols=None)[1][1] - arma_coef + ols_coef\n",
    "    else:\n",
    "        ci_lower = smresults.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "        ci_upper = smresults.conf_int(alpha=0.05, cols=None)[1][1]\n",
    "    if runtype == 'ols':\n",
    "        ci_lower = smresults.conf_int(alpha=0.05, cols=None)[0][1]\n",
    "        ci_upper = smresults.conf_int(alpha=0.05, cols=None)[1][1]\n",
    "    sd = (ci_upper - ols_coef) / 2.\n",
    "    return {\n",
    "            'coef' : ols_coef,\n",
    "            'ci_lower' : ci_lower,\n",
    "            'ci_upper' : ci_upper,\n",
    "            'sd' : sd\n",
    "    }\n",
    "\n",
    "\n",
    "def obs_temp_time_trends(annual_temps, timeframes):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe = [], [], [], []\n",
    "    for times in timeframes:\n",
    "        print('Analyzing the period from ', times[0], ' to ', times[1])\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        start_year = times[0]\n",
    "        end_year = times[1]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= end_year))[0]\n",
    "\n",
    "        for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "            years = annual_temps['year'][temp_year_range]\n",
    "            temp_values = annual_temps[obs_temps][temp_year_range]\n",
    "            results = coef_arma_cis(temp_values, years)\n",
    "            coef.append(results['coef'])\n",
    "            ci_lower.append(results['ci_lower'])\n",
    "            ci_upper.append(results['ci_upper'])\n",
    "            obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(times))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv(interim_path+'obs_time_trends.csv')\n",
    "\n",
    "\n",
    "def obs_temp_forcing_trends(forcings, annual_temps, timeframes):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe = [], [], [], []\n",
    "\n",
    "    for times in timeframes:\n",
    "        print('Analyzing the period from ', times[0], ' to ', times[1])\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        start_year = times[0]\n",
    "        end_year = times[1]\n",
    "        rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "        rf_year_range = np.where((forcings['year'] >= start_year) & (forcings['year'] <= end_year))[0]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= end_year))[0]\n",
    "        \n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                rf_values = rf_anthro[rf_num][rf_year_range]\n",
    "                temp_values = annual_temps[obs_temps][temp_year_range]\n",
    "                results = coef_arma_cis(temp_values, rf_values, runtype='ols')\n",
    "                coef.append(results['coef'])\n",
    "                ci_lower.append(results['ci_lower'])\n",
    "                ci_upper.append(results['ci_upper'])\n",
    "                rf_number.append(rf_num)\n",
    "                obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'rf_number' : rf_number,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(times))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv(interim_path+'obs_forcing_trends.csv')\n",
    "\n",
    "\n",
    "def models_forcing_time_trends(single_models, model_names, model_years):\n",
    "    coef, coef_low, coef_high, timeframe, model, dtype = [], [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        temp_year = coef_arma_cis(single_models[model_names[i]+'_t'][years], single_models['year'][years])\n",
    "        temp_forcing = coef_arma_cis(single_models[model_names[i]+'_t'][years], single_models[model_names[i]+'_f'][years], runtype='ols')\n",
    "        coef.append(temp_year['coef'])\n",
    "        coef_low.append(temp_year['ci_lower'])\n",
    "        coef_high.append(temp_year['ci_upper'])\n",
    "        timeframe.append(str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        model.append(model_names[i])\n",
    "        dtype.append('model_time')\n",
    "        coef.append(temp_forcing['coef'])\n",
    "        coef_low.append(temp_forcing['ci_lower'])\n",
    "        coef_high.append(temp_forcing['ci_upper'])\n",
    "        timeframe.append(str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        model.append(model_names[i])\n",
    "        dtype.append('model_forcing')\n",
    "    #manabe_1970_f = coef_arma_cis(df['manabe_1970_t'], df['manabe_1970_f'])\n",
    "    \n",
    "    df = pd.DataFrame({'coef' : coef,\n",
    "                       'coef_low' : coef_low,\n",
    "                       'coef_high' : coef_high,\n",
    "                       'timeframe' : timeframe,\n",
    "                       'model' : model,\n",
    "                       'dtype': dtype})\n",
    "    df.to_csv(interim_path+'single_model_trends.csv')\n",
    "\n",
    "\n",
    "def model_obs_time_diffs(single_models, model_names, model_years, annual_temps):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe, model = [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        coef, ci_lower, ci_upper = [], [], []\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "            print('Analyzing '+model_names[i]+' '+obs_temps+' diffs from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "            model_obs_diff = single_models[model_names[i]+'_t'][years] - annual_temps[obs_temps][years]            \n",
    "            results = coef_arma_cis(model_obs_diff, single_models['year'][years])\n",
    "            coef.append(results['coef'])\n",
    "            ci_lower.append(results['ci_lower'])\n",
    "            ci_upper.append(results['ci_upper'])\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv(interim_path+'model_obs_time_diffs.csv')    \n",
    "\n",
    "obs_temp_time_trends(annual_temps, timeframes)\n",
    "obs_temp_forcing_trends(forcings, annual_temps, timeframes)\n",
    "models_forcing_time_trends(single_models, model_names, model_years)\n",
    "model_obs_time_diffs(single_models, model_names, model_years, annual_temps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_forcing_ensemble(forcings, annual_temps, start_year, anom_period, path=\"./\"):\n",
    "    rf_year_range = np.where((forcings['year'] >= start_year) & (forcings['year'] <= 2017))[0]\n",
    "    temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= 2017))[0]\n",
    "    rf_anthro = forcings['rf_anthro'][rf_year_range]\n",
    "    rf_anthro_anoms = rf_anthro - rf_anthro[0:anom_period].mean(axis=0)\n",
    "    rf_anthro_anoms = np.swapaxes(rf_anthro_anoms,0,1)\n",
    "\n",
    "    df_names = ('hadcrut4_df', 'gistemp_df', 'noaa_df', 'berkeley_df', 'cowtan_way_df')\n",
    "    dfs ={}\n",
    "\n",
    "    for df_names,obs_temps in zip(df_names, ['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "        dfs[df_names] = pd.DataFrame()\n",
    "        dfs[df_names]['year'] = annual_temps['year'][temp_year_range]\n",
    "        temps = annual_temps[obs_temps][temp_year_range].values\n",
    "        anoms = temps - temps[0:anom_period].mean(axis=0)\n",
    "        dfs[df_names]['temp'] = anoms\n",
    "        for rf_num in range(1000):\n",
    "            dfs[df_names]['forcing_'+str(rf_num)] = rf_anthro_anoms[rf_num]\n",
    "        \n",
    "        dfs[df_names].to_csv(path+obs_temps + '_' + 'forcings'+str(start_year)+'.csv')\n",
    "\n",
    "output_forcing_ensemble(forcings, annual_temps, 1970, 20, path=\"../data/processed/FAR_spaghetti/\")\n",
    "output_forcing_ensemble(forcings, annual_temps, 1988, 20, path=\"../data/processed/Hansen_spaghetti/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1970  to  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  newparams = ((1-np.exp(-params))/\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:607: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (1+np.exp(-params))).copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1971  to  2000\n",
      "Analyzing the period from  1972  to  2000\n",
      "Analyzing the period from  1975  to  2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:634: RuntimeWarning: divide by zero encountered in log\n",
      "  invarcoefs = -np.log((1-params)/(1+params))\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/kalmanf/kalmanfilter.py:654: RuntimeWarning: divide by zero encountered in log\n",
      "  R_mat, T_mat)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:243: RuntimeWarning: invalid value encountered in subtract\n",
      "  **kwargs)).imag/2./hess[i, j]\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tools/numdiff.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  **kwargs)).imag/2./hess[i, j]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the period from  1977  to  2017\n",
      "Analyzing the period from  1981  to  2017\n",
      "Analyzing the period from  1988  to  2017\n",
      "Analyzing the period from  1990  to  2017\n",
      "Analyzing the period from  1993  to  2017\n",
      "Analyzing the period from  1995  to  2017\n",
      "Analyzing the period from  2001  to  2017\n",
      "Analyzing the period from  2007  to  2017\n"
     ]
    }
   ],
   "source": [
    "def model_forcing_rate(single_models, model_names, model_years):\n",
    "    coef, coef_low, coef_high, timeframe, model = [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        forcing_rate = coef_arma_cis(single_models[model_names[i]+'_f'][years], single_models['year'][years])\n",
    "        coef.append(forcing_rate['coef'])\n",
    "        coef_low.append(forcing_rate['ci_lower'])\n",
    "        coef_high.append(forcing_rate['ci_upper'])\n",
    "        timeframe.append(str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        model.append(model_names[i])\n",
    "    #manabe_1970_f = coef_arma_cis(df['manabe_1970_t'], df['manabe_1970_f'])\n",
    "    \n",
    "    df = pd.DataFrame({'coef' : coef,\n",
    "                       'coef_low' : coef_low,\n",
    "                       'coef_high' : coef_high,\n",
    "                       'timeframe' : timeframe,\n",
    "                       'model' : model})\n",
    "    df.to_csv(interim_path+'single_model_forcing_rate.csv')\n",
    "\n",
    "def obs_forcing_rate(forcings, annual_temps, timeframes):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe = [], [], [], []\n",
    "    \n",
    "    for times in timeframes:\n",
    "        print('Analyzing the period from ', times[0], ' to ', times[1])\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        start_year = times[0]\n",
    "        end_year = times[1]\n",
    "        rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "        rf_year_range = np.where((forcings['year'] >= start_year) & (forcings['year'] <= end_year))[0]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= start_year) & (annual_temps['year'] <= end_year))[0]\n",
    "        \n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                rf_values = rf_anthro[rf_num][rf_year_range]\n",
    "                years = annual_temps['year'][temp_year_range]\n",
    "                results = coef_arma_cis(rf_values, years)\n",
    "                coef.append(results['coef'])\n",
    "                ci_lower.append(results['ci_lower'])\n",
    "                ci_upper.append(results['ci_upper'])\n",
    "                rf_number.append(rf_num)\n",
    "                obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'rf_number' : rf_number,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(times))\n",
    "    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv(interim_path+'obs_forcing_rate.csv')\n",
    "\n",
    "model_forcing_rate(single_models, model_names, model_years)\n",
    "obs_forcing_rate(forcings, annual_temps, timeframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_forcing_timeseries(forcings):\n",
    "    forcings['rf_total'].shape\n",
    "    std = np.std(forcings['rf_total'], axis=1)\n",
    "    mean = np.mean(forcings['rf_total'], axis=1)\n",
    "    \n",
    "    df = pd.DataFrame({'year' : forcings['year'],\n",
    "                       'forcing_mean' : mean,\n",
    "                       'forcing_std' : std})\n",
    "    df.to_csv(interim_path+'forcing_timeseries.csv')\n",
    "\n",
    "obs_forcing_timeseries(forcings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing manabe_1970 from 1970 to 2000\n",
      "Analyzing mitchell_1970 from 1970 to 2000\n",
      "Analyzing benson_1970 from 1970 to 2000\n",
      "Analyzing rasool_schneider_1971 from 1971 to 2000\n",
      "Analyzing sawyer_1972 from 1972 to 2000\n",
      "Analyzing broecker_1975 from 1975 to 2010\n",
      "Analyzing nordhaus_1977 from 1977 to 2017\n",
      "Analyzing schneider_thompson_1981 from 1981 to 2017\n",
      "Analyzing hansen_1981_1 from 1981 to 2017\n",
      "Analyzing hansen_1981_2a from 1981 to 2017\n",
      "Analyzing hansen_1988_a from 1988 to 2017\n",
      "Analyzing hansen_1988_b from 1988 to 2017\n",
      "Analyzing hansen_1988_c from 1988 to 2017\n",
      "Analyzing manabe_stouffer_1993 from 1993 to 2017\n",
      "Analyzing far_ebm_best from 1990 to 2017\n",
      "Analyzing far_ebm_high from 1990 to 2017\n",
      "Analyzing far_ebm_low from 1990 to 2017\n",
      "Analyzing sar_ebm_best from 1995 to 2017\n",
      "Analyzing sar_ebm_high from 1995 to 2017\n",
      "Analyzing sar_ebm_low from 1995 to 2017\n",
      "Analyzing tar_ebm_best from 2001 to 2017\n",
      "Analyzing tar_ebm_high from 2001 to 2017\n",
      "Analyzing tar_ebm_low from 2001 to 2017\n",
      "Analyzing ar4_mmm_best from 2007 to 2017\n",
      "Analyzing ar4_mmm_high from 2007 to 2017\n",
      "Analyzing ar4_mmm_low from 2007 to 2017\n"
     ]
    }
   ],
   "source": [
    "def model_skill(obs_trend, pred_trend):\n",
    "    skill = 1 - ((obs_trend - pred_trend)**2 / obs_trend**2) ** (0.5)\n",
    "    return skill\n",
    "\n",
    "\n",
    "def model_time_skill_scores(single_models, model_names, model_years, annual_temps):\n",
    "    skill_mean, skill_median, skill_5th, skill_95th, timeframe, model = [], [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        skill = []\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        model_trend = coef_arma_cis(single_models[model_names[i]+'_t'][years], single_models['year'][years])\n",
    "        for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "            print('Analyzing '+model_names[i]+' '+obs_temps+' diffs from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "            obs_trend = coef_arma_cis(annual_temps[obs_temps][years], annual_temps['year'][years])\n",
    "            model_monte_carlo = np.random.normal(model_trend['coef'], model_trend['sd'], 100)\n",
    "            obs_monte_carlo = np.random.normal(obs_trend['coef'], obs_trend['sd'], 100)\n",
    "            for j in range(100):\n",
    "                skill.append(model_skill(obs_monte_carlo[j], model_monte_carlo[j]))\n",
    "        df = pd.DataFrame({'skill' : skill})\n",
    "        skill_mean.append(df['skill'].mean())\n",
    "        skill_median.append(df['skill'].median())\n",
    "        skill_5th.append(df['skill'].quantile(0.05))\n",
    "        skill_95th.append(df['skill'].quantile(0.95))    \n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))\n",
    "    \n",
    "    df = pd.DataFrame({'skill_mean' : skill_mean,\n",
    "                       'skill_median' : skill_median,\n",
    "                       'skill_5th' : skill_5th,\n",
    "                       'skill_95th' : skill_95th,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    df.to_csv(interim_path+'model_time_skill_scores.csv')\n",
    "    \n",
    "\n",
    "def model_tcr_skill_scores(single_models, model_names, model_years, annual_temps, forcings):\n",
    "    skill_mean, skill_median, skill_5th, skill_95th, timeframe, model = [], [], [], [], [], []\n",
    "    rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        skill = []\n",
    "        years = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        model_t = single_models[model_names[i]+'_t'][years]\n",
    "        model_f = single_models[model_names[i]+'_f'][years]\n",
    "        model_tcr = coef_arma_cis(model_t, model_f, runtype='ols')\n",
    "        rf_year_range = np.where((forcings['year'] >= model_years[i][0]) & (forcings['year'] <= model_years[i][1]))[0]\n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                obs_f = rf_anthro[rf_num][rf_year_range]\n",
    "                obs_t = annual_temps[obs_temps][years]\n",
    "                obs_tcr = coef_arma_cis(obs_t, obs_f, runtype='ols')\n",
    "                model_monte_carlo = np.random.normal(model_tcr['coef'], model_tcr['sd'], 100)\n",
    "                obs_monte_carlo = np.random.normal(obs_tcr['coef'], obs_tcr['sd'], 100)\n",
    "                for j in range(100):\n",
    "                    skill.append(model_skill(obs_monte_carlo[j], model_monte_carlo[j]))\n",
    "        df = pd.DataFrame({'skill' : skill})\n",
    "        skill_mean.append(df['skill'].mean())\n",
    "        skill_median.append(df['skill'].median())        \n",
    "        skill_5th.append(df['skill'].quantile(0.05))\n",
    "        skill_95th.append(df['skill'].quantile(0.95))        \n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))\n",
    "    \n",
    "    df = pd.DataFrame({'skill_mean' : skill_mean,\n",
    "                       'skill_median' : skill_median,\n",
    "                       'skill_5th' : skill_5th,\n",
    "                       'skill_95th' : skill_95th,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    df.to_csv(interim_path+'model_tcr_skill_scores.csv')    \n",
    "    \n",
    "    \n",
    "\n",
    "model_time_skill_scores(single_models, model_names, model_years, annual_temps)\n",
    "model_tcr_skill_scores(single_models, model_names, model_years, annual_temps, forcings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_obs_forcing_diffs(single_models, model_names, model_years, forcings, annual_temps):\n",
    "    coef_mean, coef_sd, ci_mean, timeframe, model = [], [], [], [], []\n",
    "    for i in range(len(model_names)):\n",
    "        print('Analyzing '+model_names[i]+' diffs from '+str(model_years[i][0])+' to '+str(model_years[i][1]))\n",
    "        coef, ci_lower, ci_upper, rf_number, obs_series = [], [], [], [], []\n",
    "        model_year_range = single_models['year'].between(model_years[i][0], model_years[i][1])\n",
    "        rf_anthro = np.swapaxes(forcings['rf_anthro'],0,1)   \n",
    "        rf_year_range = np.where((forcings['year'] >= model_years[i][0]) & (forcings['year'] <= model_years[i][1]))[0]\n",
    "        temp_year_range = np.where((annual_temps['year'] >= model_years[i][0]) & (annual_temps['year'] <= model_years[i][1]))[0]\n",
    "        model_temp = single_models[model_names[i]+'_t'][model_year_range]\n",
    "        model_rf = single_models[model_names[i]+'_f'][model_year_range]\n",
    "\n",
    "        for rf_num in range(1000):\n",
    "            for obs_temps in (['hadcrut4', 'gistemp', 'noaa', 'berkeley', 'cowtan_way']):\n",
    "                obs_rf = rf_anthro[rf_num][rf_year_range]\n",
    "                obs_temp = annual_temps[obs_temps][temp_year_range]\n",
    "                temp_diff = model_temp - obs_temp\n",
    "                rf_diff = model_rf - obs_rf\n",
    "                results = coef_arma_cis(temp_diff, rf_diff, runtype='ols')\n",
    "                coef.append(results['coef'])\n",
    "                ci_lower.append(results['ci_lower'])\n",
    "                ci_upper.append(results['ci_upper'])\n",
    "                rf_number.append(rf_num)\n",
    "                obs_series.append(obs_temps)\n",
    "        df = pd.DataFrame({'coef' : coef,\n",
    "                           'ci_lower' : ci_lower,\n",
    "                           'ci_upper' : ci_upper,\n",
    "                           'rf_number' : rf_number,\n",
    "                           'obs_series' : obs_series})\n",
    "        df['ci_val'] = df['coef'] - df['ci_lower']\n",
    "        coef_mean.append(df['coef'].mean())\n",
    "        coef_sd.append(df['coef'].std())\n",
    "        ci_mean.append(df['ci_val'].mean())\n",
    "        timeframe.append(str(model_years[i]))\n",
    "        model.append(str(model_names[i]))    \n",
    "    df = pd.DataFrame({'coef_mean' : coef_mean,\n",
    "                       'coef_sd' : coef_sd,\n",
    "                       'ci_mean' : ci_mean,\n",
    "                       'model' : model,\n",
    "                       'timeframe' : timeframe})\n",
    "    uncertainty = ((df['coef_sd']*2)**2 + df['ci_mean']**2)**(0.5)\n",
    "    df['coef_low'] = df['coef_mean'] - uncertainty\n",
    "    df['coef_high'] = df['coef_mean'] + uncertainty\n",
    "    df.to_csv(interim_path+'model_obs_forcing_trend_diffs.csv')\n",
    "\n",
    "model_obs_forcing_diffs(single_models, model_names, model_years, forcings, annual_temps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
